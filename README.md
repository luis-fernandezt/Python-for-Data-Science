
# Python for Data Science

Resumen de apuntes de Python para ciencia de datos utilizando Jupyter Notebook y Visual Studio Code.

---

## ğŸ“¦ LibrerÃ­as utilizadas

### InstalaciÃ³n con pip:

```bash
pip install pandas matplotlib seaborn numpy statsmodels scikit-learn dataclasses getweather
```

### LibrerÃ­as importadas:

- **pandas** â†’ `import pandas as pd`
- **numpy** â†’ `import numpy as np`
- **matplotlib** â†’ `import matplotlib.pyplot as plt` o `import matplotlib.pyplot as pp`
- **seaborn** â†’ `import seaborn as sns`
- **statsmodels** â†’ `import statsmodels.api as sm` y `from statsmodels.formula.api import ols`
- **scikit-learn** â†’ `from sklearn.model_selection import train_test_split`, `from sklearn.neighbors import KNeighborsClassifier`
- **datetime** â†’ `from datetime import date, time, datetime, timedelta`
- **math** â†’ `import math`
- **os / path** â†’ `import os`, `from os import path`
- **shutil / zipfile** â†’ `import shutil`, `from shutil import make_archive`, `from zipfile import ZipFile`
- **calendar** â†’ `import calendar`
- **json / urllib** â†’ `import json`, `import urllib.request`
- **collections** â†’ `import collections`, `@dataclass`, `namedtuple`
- **itertools** â†’ `import itertools`
- **getweather** â†’ `import getweather` *(librerÃ­a personalizada o externa no estÃ¡ndar)*

---

## ğŸ› ï¸ Comandos y Sintaxis Ãštil

> Ordenados de menor a mayor complejidad y agrupados por funcionalidad.

### ğŸ“˜ Entrada / Salida y estructuras bÃ¡sicas

```python
print("Hello World")  # salida simple
mylist = [0, 1, "two", 3.2, False]
mydict = {"one": 1, "two": 2}
del mylist
del mydict
```

### ğŸ“‚ Archivos

```python
file = open("file.txt", "w+")  # escribir
file = open("file.txt", "a+")  # agregar
file = open("file.txt", "r")   # leer
file.readlines()
file.close()
```

### ğŸ“ Tipos de datos y operaciones comunes

```python
len(data)
type(data)
sorted(data)
data.sort()
data.append("x")
data.remove("x")
data.insert(0, "x")
data.extend(["a", "b"])
```

### ğŸ” Pandas: limpieza y exploraciÃ³n de datos

```python
pd.read_csv("data.csv")
data.head()
data.tail()
data.info()
data.shape
data.columns
data.dtypes
data.index
data.isna().sum()
data.dropna()
data.duplicated().sum()
data["col"].value_counts(normalize=True)
data["col"].dtype
```

### ğŸ” Pandas: filtrado y agrupaciÃ³n

```python
data["Year"] == 2025
data.loc[data["Year"] == 2025, :]
data.groupby("Year").count()
data.sort_values("Count", ascending=False)
data.query("col > 10")
```

### ğŸ§ª EstadÃ­stica bÃ¡sica

```python
np.mean(data["value"])
np.min(data)
np.max(data)
np.nanmin(data)
np.nanmax(data)
np.isnan(data)
np.percentile(data, 2.5)
np.percentile(data, 97.5)
```

### ğŸ“Š VisualizaciÃ³n

```python
data.plot.barh(x="Year", y="Count")
sns.barplot(x="col1", y="col2", data=data, ci=False)
sns.countplot(x="col", data=data)
sns.histplot(data=data, x="col", hue="group")
sns.pairplot(data)
plt.hist(data["col"])
plt.scatter(x=data["x"], y=data["y"], s=5)
plt.xlabel("x-axis")
plt.ylabel("y-axis")
plt.legend(["name1", "name2"])
plt.xlim(0, 100)
plt.axhline(0)
plt.show()
```

### ğŸ“ˆ Modelado

```python
X_train, X_test, y_train, y_test = train_test_split(X, y)
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
knn.predict(X_test)
knn.score(X_test, y_test)

model = ols(formula="value1 ~ value2", data=data).fit()
model.summary()
sm.qqplot(model.resid, line='s')
```

### ğŸ§­ Fechas y tiempos

```python
datetime.now()
date.today()
datetime.now().strftime("%Y-%m-%d")
datetime.now() + timedelta(days=10)
datetime.now() - timedelta(weeks=1)
```

### ğŸŒ€ Control de flujo

```python
for x in range(10):
    print(x)

while x < 5:
    print(x)
    x += 1

days = ["Mon", "Tue", "Wed"]
for i, d in enumerate(days):
    print(i, d)

if x > 0:
    print("Positive")
elif x == 0:
    print("Zero")
else:
    print("Negative")
```

---

## ğŸŒ Webpages y recursos en lÃ­nea

- [DocumentaciÃ³n datetime Python](https://docs.python.org/3.6/library/datetime.html#strftime-and-strptime-behavior)
- [DocumentaciÃ³n JSON Python](https://docs.python.org/es/3/library/json.html)
- [Kaggle](https://www.kaggle.com/)
- [USGS Earthquake GeoJSON feed](https://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php)
- [HTML Viewer](https://html.onlineviewer.net/)

---

## ğŸ“š Referencias BibliogrÃ¡ficas

- McKinney, W. (2018). *Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython*.
- VanderPlas, J. (2016). *Python Data Science Handbook*.
- GÃ©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*.
- Hunter, J.D. (2007). *Matplotlib: A 2D Graphics Environment*. Computing in Science & Engineering.
- Pedregosa, F., et al. (2011). *Scikit-learn: Machine Learning in Python*. Journal of Machine Learning Research.
- Official Python Documentation: https://docs.python.org
- Seaborn Documentation: https://seaborn.pydata.org/
- Statsmodels Documentation: https://www.statsmodels.org/


## ğŸ“ Glosario de TÃ©rminos y FÃ³rmulas

| **TÃ©rmino**                            | **DefiniciÃ³n**                                                                                              |
|----------------------------------------|-------------------------------------------------------------------------------------------------------------|
| Media (Î¼)                              | Î¼ = (1/n) âˆ‘áµ¢ xáµ¢Â Â # promedio de todos los valores.                                                             |
| Varianza (ÏƒÂ²)                          | ÏƒÂ² = (1/n) âˆ‘áµ¢ (xáµ¢ - Î¼)Â²Â Â # medida de dispersiÃ³n de los valores respecto a la media.                          |
| DesviaciÃ³n estÃ¡ndar (Ïƒ)                | Ïƒ = âˆš[ÏƒÂ²]Â Â # raÃ­z cuadrada de la varianza.                                                                  |
| Z-score                                | z = (x - Î¼) / ÏƒÂ Â # cuÃ¡ntas desviaciones estÃ¡ndar se aleja el valor x de la media.                           |
| Percentil                              | Valor por debajo del cual cae un p% de las observaciones.                                                   |
| Intervalo de confianza (95%)           | IC = xÌ„ Â± 1.96 * (Ïƒ / âˆšn)Â Â # rango donde se espera que estÃ© la media poblacional con 95% de confianza.      |
| RegresiÃ³n lineal (OLS)                 | Å· = Î²â‚€ + Î²â‚ xÂ Â # modelo de regresiÃ³n donde Å· es el valor predicho.                                         |
| Error estÃ¡ndar de Î²â‚                   | SE(Î²â‚) = Ïƒ / âˆš(âˆ‘ (xáµ¢ - xÌ„)Â²)Â Â # precisiÃ³n de la estimaciÃ³n de la pendiente.                                  |
| Coeficiente de correlaciÃ³n (r)         | r = Cov(X,Y) / (Ïƒ_X Ïƒ_Y)Â Â # fuerza y direcciÃ³n de la relaciÃ³n lineal entre X y Y.                           |
| Coeficiente de determinaciÃ³n (RÂ²)      | RÂ² = 1 - SSE/SSTÂ Â # proporciÃ³n de varianza de Y explicada por el modelo.                                    |
| train_test_split                       | FunciÃ³n de scikit-learn para separar datos en conjuntos de entrenamiento y prueba.                          |
| KNeighborsClassifier                   | Algoritmo de clasificaciÃ³n que asigna la clase segÃºn la mayorÃ­a de los k vecinos mÃ¡s cercanos.               |

